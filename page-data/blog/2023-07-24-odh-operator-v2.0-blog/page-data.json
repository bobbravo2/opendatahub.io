{"componentChunkName":"component---src-templates-blog-post-tsx","path":"/blog/2023-07-24-odh-operator-v2.0-blog/","result":{"data":{"markdownRemark":{"id":"6ebaac92-6a30-58af-ab74-578bb78b8ce1","excerpt":"Starting with ODH 1.8, we are excited to announce a new version of our OpenDataHub operator(v2.0.0) that introduces a\ncustom resource called DataScienceCluster…","html":"<p>Starting with ODH 1.8, we are excited to announce a new version of our OpenDataHub operator(v2.0.0) that introduces a\ncustom resource called <strong>DataScienceCluster</strong>.  This is an <strong>alpha release</strong> exclusively available on the “fast” channel\nand subject to evolve continuously.</p>\n<h2>Introducing DataScienceCluster</h2>\n<p>The DataScienceCluster custom resource allows fine-grained control over various data science components deployed within\nyour ODH Deployment. It encapsulates various data science applications managed through Kustomize deployments. With this\ncustom resource, you can <strong>enable</strong> and <strong>disable</strong> any of the integrated components at any time, thereby giving you\ncontrol over your data science environment. Every core component provided by ODH is currently exposed by the\nDataScienceCluster.</p>\n<p>Here is an example of the DataScienceCluster custom resource:</p>\n<pre><code>apiVersion: datasciencecluster.opendatahub.io/v1alpha1\nkind: DataScienceCluster\nmetadata:\n  name: default\nspec:\n  components:\n    dashboard:\n      enabled: true\n    datasciencepipelines:\n      enabled: false\n    distributedworkloads:\n      enabled: true\n    kserve:\n      enabled: false\n    modelmeshserving:\n      enabled: false\n    workbenches:\n      enabled: true\n</code></pre>\n<h2>Understanding the Components</h2>\n<p>Each component in the <strong>DataScienceCluster</strong> spec represents a data science application also provided through ODH\nmanifests. Let's take a quick look at what each of these components does:</p>\n<ul>\n<li><strong>dashboard</strong>: A web dashboard that displays installed Open Data Hub components with easy access to component APIs</li>\n<li><strong>datasciencepipelines</strong>: Pipeline solution for end to end MLOps workflows that support the Kubeflow Pipelines SDK and Tekton.</li>\n<li><strong>distributedworkloads(incubation)</strong>: This enables you to distribute your computational workloads across different nodes in your cluster, enhancing performance and efficiency.</li>\n<li><strong>kserve(incubation):</strong> This is for serving your models. KServe provides a serverless framework to deploy machine learning models with the potential to scale based on demand.</li>\n<li><strong>modelmeshserving:</strong> This enables you to serve your models using ModelMesh, which is designed to facilitate high-scale, high-density, and frequently changing model use cases.</li>\n<li><strong>workbenches:</strong> This component enables you to set up your data science workbenches or Jupyter notebooks for interactive data analysis.</li>\n</ul>\n<p>Each of these components can be <strong>enabled</strong> or <strong>disabled</strong> at will by simply changing the enabled field to true or false.\nThis gives you the flexibility to customize your data science environment according to the specific needs of your project.</p>\n<h2>Upcoming Features in DataScienceCluster</h2>\n<p>We are dedicated to continually improving the DataScienceCluster custom resource, and we are thrilled to share some\nupcoming enhancements that we believe will bring even more versatility and power to your data science workflows.</p>\n<h3>Integration with New Components</h3>\n<p>In the upcoming release, we plan to expand the number of components that can be managed through DataScienceCluster.\nWe are currently evaluating several new applications and tools which can provide additional functionality and capabilities\nto your data science workflows. We have already integrated some incubating applications (kserve and distributed workloads)\ninto the new operator. Our goal is to ensure that DataScienceCluster remains a comprehensive, one-stop solution for managing\nyour data science environment.</p>\n<h3>Making Component Fields Configurable</h3>\n<p>In an effort to provide more granular control over individual components, we are working on a feature to make component\nfields configurable. This means that you will be able to adjust individual parameters within each component, beyond just\nenabling or disabling them. With this feature, you can fine-tune each component to suit your specific needs, providing\nmore flexibility and control than before.</p>\n<h3>Improved Logging and Eventing</h3>\n<p>To enhance observability and debugging, we are improving the logging and eventing capabilities of the DataScienceCluster\ncustom resource. These enhancements will provide more insight into the performance and state of your components, helping\nyou to detect and diagnose issues more quickly and effectively. The logging improvements will provide more detailed and\ncontextual information, while enhanced eventing will help you monitor the state of your cluster in real-time.</p>\n<h2>Getting Involved and Additional Resources</h2>\n<ul>\n<li><strong>Try it out</strong> : Try out the new operator installation using the steps give in our <a href=\"https://opendatahub.io/docs/quick-installation-new-operator/#installing-the-new-open-data-hub-operator\">installation Guide</a>.</li>\n</ul>\n<p>If you want to upgrade from existing installation, use our <a href=\"https://opendatahub.io/docs/quick-installation/\">Upgrade Guide</a>\nunder section <strong>Upgrade to new operator(version 2.X)</strong>.</p>\n<ul>\n<li><strong>Contribution Guide:</strong> If you're interested in contributing to the development of DataScienceCluster, please review</li>\n</ul>\n<p>our <a href=\"https://github.com/opendatahub-io/opendatahub-operator/blob/feature-rearchitecture/README.md#developer-guide\">Contribution Guide</a>. This guide provides detailed instructions on how to contribute, from setting up your development\nenvironment to running e2e tests locally.</p>\n<ul>\n<li><strong>Design Document:</strong> For an in-depth understanding of the design and architecture of DataScienceCluster, check out our</li>\n</ul>\n<p><a href=\"https://github.com/opendatahub-io/opendatahub-operator/blob/feature-rearchitecture/docs/DESIGN.md\">Design Document</a>.</p>\n<ul>\n<li><strong>Codebase:</strong> To open issues and review code, visit <a href=\"https://github.com/opendatahub-io/opendatahub-operator/tree/feature-rearchitecture\">opendatahub-operator</a> repo.</li>\n</ul>\n<p>In conclusion, the introduction of the <strong>DataScienceCluster</strong> custom resource represents a significant step forward in\nstreamlining and managing data science workflows for Open Data Hub. We're excited about the upcoming features and\nimprovements and look forward to seeing how the community will utilize and enhance DataScienceCluster.\nThank you for your continued support, and we look forward to your contributions and feedback.</p>","frontmatter":{"title":"Exploring the DataScienceCluster: A New Custom Resource in OpenDataHub(incubation)","author":"VaishnaviHire","categories":"features, release, documentation","preview":"ODH is now incubating a new version(v2.0.0) of Operator","date":"July 24, 2023"}}},"pageContext":{"id":"6ebaac92-6a30-58af-ab74-578bb78b8ce1"}},"staticQueryHashes":["2604506565"],"slicesMap":{}}